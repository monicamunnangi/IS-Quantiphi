{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.data import BucketIterator\n",
    "\n",
    "random.seed(696)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = pd.read_csv('patient_data.csv')\n",
    "patients = patients.fillna(method='backfill')\n",
    "patients = patients.fillna(patients.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_indices(pos_len, neg_len, ratios):\n",
    "    train, val, test = ratios[0], ratios[1], ratios[2]\n",
    "    pos_tr, neg_tr = int(round(pos_len * train)), int(round(neg_len * train))\n",
    "    pos_val, neg_val = int(round(pos_len * val)), int(round(neg_len * val))\n",
    "    pos_test, neg_test = int(round(pos_len * test)), int(round(neg_len * test))\n",
    "    return ((pos_tr, pos_val, pos_test), (neg_tr, neg_val, neg_test))\n",
    "    \n",
    "    \n",
    "def split_dataset(patients, ratios):\n",
    "    positive = patients[patients['SepsisLabel'] == 1]['pid'].unique().tolist()\n",
    "    negative = [i for i in range(1, 5000+1) if i not in positive]\n",
    "    random.shuffle(positive)\n",
    "    random.shuffle(negative)\n",
    "    pos_idx, neg_idx = get_split_indices(len(positive), len(negative), ratios)\n",
    "    \n",
    "    train = positive[0:pos_idx[0]] + negative[0:neg_idx[0]]\n",
    "    val = positive[pos_idx[0]:pos_idx[0] + pos_idx[1]] + negative[neg_idx[0]:neg_idx[0] + neg_idx[1]]\n",
    "    test = positive[pos_idx[0] + pos_idx[1]:] + negative[neg_idx[0] + neg_idx[1]:]\n",
    "    \n",
    "    train_dict, val_dict, test_dict = {}, {}, {}\n",
    "    for pid in train:\n",
    "        train_dict[pid] = patients[patients['pid'] == pid]\n",
    "    for pid in val:\n",
    "        val_dict[pid] = patients[patients['pid'] == pid]\n",
    "    for pid in test:\n",
    "        test_dict[pid] = patients[patients['pid'] == pid]\n",
    "    \n",
    "    return train_dict, val_dict, test_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose patient observation windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def process_patient(patient, max_len, window_marker=70):\n",
    "    patient = patient.reset_index()\n",
    "    obs_len = patient.shape[0]\n",
    "    \n",
    "    if(patient[patient['SepsisLabel'] == 1].shape[0]):\n",
    "        sepsis_idx = list(patient[patient['SepsisLabel']==1].index)[0]\n",
    "        if obs_len > max_len: return process_longer_obs(patient, sepsis_idx, max_len, marker=window_marker)\n",
    "        if obs_len < max_len: return process_shorter_obs(patient, sepsis_idx, max_len)\n",
    "    else:\n",
    "        if obs_len > max_len:\n",
    "            return patient.iloc[0:max_len, 2:]\n",
    "        if obs_len < max_len:\n",
    "            p = patient.iloc[:, :]\n",
    "            for i in range(max_len - obs_len):\n",
    "                p = p.append(patient.iloc[-1, :])\n",
    "            return p.iloc[:, 2:]\n",
    "    return patient.iloc[:, 2:]\n",
    "\n",
    "def process_shorter_obs(patient, sepsis_idx, max_len):\n",
    "    p = pd.DataFrame()\n",
    "    p = p.append(patient)\n",
    "    for i in range(max_len - patient.shape[0]):\n",
    "        p = p.append(p.iloc[-1, :])\n",
    "    return p.reset_index().iloc[:, 3:]\n",
    "        \n",
    "def process_longer_obs(patient, sepsis_idx, max_len, marker=70):\n",
    "    p = pd.DataFrame()\n",
    "    avail_before = sepsis_idx - 1\n",
    "    avail_after = patient.shape[0] - sepsis_idx\n",
    "    need_before = int(max_len * marker/100)\n",
    "    need_after = int(max_len * (100 - marker)/100) - 1\n",
    "   \n",
    "    if avail_before >= need_before and avail_after >= need_after:\n",
    "        p = p.append(patient.iloc[avail_before - need_before:avail_before+1, :])\n",
    "        p = p.append(patient.iloc[sepsis_idx, :])\n",
    "        p = p.append(patient.iloc[sepsis_idx+1 : sepsis_idx + need_after, :])\n",
    "    \n",
    "    elif avail_before >= need_before and avail_after <= need_after:\n",
    "        p = p.append(patient.iloc[avail_before - need_before:avail_before+1, :])\n",
    "        p = p.append(patient.iloc[sepsis_idx, :])\n",
    "        p = p.append(patient.iloc[sepsis_idx + 1:, :])\n",
    "        for i in range(max_len - p.shape[0]):\n",
    "            p = p.append(p.iloc[-1, :])\n",
    "    \n",
    "    elif avail_before <= need_before and avail_after >= need_after:\n",
    "        p = p.append(patient.iloc[0:avail_before, :])\n",
    "        p = p.append(patient.iloc[sepsis_idx, :])\n",
    "        p = p.append(patient.iloc[sepsis_idx+1 : sepsis_idx + need_after, :])\n",
    "        for i in range(max_len - p.shape[0]):\n",
    "            p = p.concat([p.iloc[0, :], p], ignore_index = True)\n",
    "    \n",
    "    return p.reset_index().iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatientDataset(Dataset):\n",
    "    def __init__(self, patient_dict, max_obs_len, window_marker):\n",
    "        self.patient_dict = patient_dict\n",
    "        self.num_patients = len(patient_dict)\n",
    "        self.pids = list(patient_dict.keys())\n",
    "        self.max_obs_len = max_obs_len\n",
    "        self.window_marker = window_marker\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_patients\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patient = self.patient_dict[self.pids[idx]]\n",
    "        patient = process_patient(patient, self.max_obs_len, self.window_marker)\n",
    "        patient_features = torch.FloatTensor(patient.iloc[:, 1:-1].values)\n",
    "        patient_labels = torch.FloatTensor(patient['SepsisLabel'])\n",
    "        self.num_patients -= 1\n",
    "        return patient_features, patient_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(patient_dict, max_obs_len, batch_size, shuffle=True, window_marker=70):\n",
    "    return DataLoader(PatientDataset(patient_dict, max_obs_len, window_marker), batch_size, shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training and evaluation setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(prediction, truth):\n",
    "    confusion_vector = prediction/truth\n",
    "    true_positives = torch.sum(confusion_vector == 1).item()\n",
    "    false_positives = torch.sum(confusion_vector == float('inf')).item()\n",
    "    true_negatives = torch.sum(torch.isnan(confusion_vector)).item()\n",
    "    false_negatives = torch.sum(confusion_vector == 0).item()\n",
    "    return true_positives, false_positives, true_negatives, false_negatives\n",
    "\n",
    "def check_accuracy(model, loader, group):\n",
    "    print('Checking ' + group + ' accuracy!')\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    tp, fp, tn, fn, precision, recall, f1 = 0, 0, 0, 0, 0 ,0, 0\n",
    "    model.eval()\n",
    "    for t, (x, y) in enumerate(loader):\n",
    "        scores = model(x)\n",
    "        rounded_preds = torch.round(torch.sigmoid(scores))\n",
    "        num_correct += (rounded_preds == y).sum()\n",
    "        num_samples += y.size(0) * y.size(1)\n",
    "        tp_t, fp_t, tn_t, fn_t = confusion_matrix(rounded_preds, y)\n",
    "        tp += tp_t\n",
    "        fp += fp_t\n",
    "        tn += tn_t\n",
    "        fn += fn_t\n",
    "\n",
    "    acc = float(num_correct) / num_samples\n",
    "    print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "    print('TP = ', tp, ', FP = ', fp, ', TN = ', tn, ', FN = ', fn)\n",
    "    if tp != 0:\n",
    "        precision = tp/(tp + fp)\n",
    "        recall = tp/(tp + fn)\n",
    "        f1 = 2 * ((precision * recall)/(precision + recall))\n",
    "    print('Precision = ', precision, ', Recall = ', recall, ', F1 Score = ', f1)\n",
    "    print()\n",
    "    return 100*acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_fn, train_dict, val_dict, max_obs_len, batch_size, epochs=1, print_every=50, window_marker=70):\n",
    "    train_history, val_history = [], []\n",
    "    for e in range(epochs):\n",
    "        print('Epoch: ', e+1)\n",
    "        for t, (x, y) in enumerate(data_loader(train_dict, max_obs_len, batch_size, window_marker)):\n",
    "            model.train()\n",
    "            scores = model(x)\n",
    "            loss = loss_fn(scores, y)\n",
    "            \n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        train_history.append(check_accuracy(model, data_loader(train_dict, max_obs_len, batch_size, window_marker), 'train'))\n",
    "        val_history.append(check_accuracy(model, data_loader(val_dict, max_obs_len, batch_size, window_marker), 'val'))\n",
    "        print()\n",
    "    return (train_history, val_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_weight(patient_dict):\n",
    "    subset = patients[patients['pid'].isin(list(patient_dict.keys()))]\n",
    "    total_samples = len(subset)\n",
    "    pos_samples = subset[subset['SepsisLabel'] == 1]['pid'].count()\n",
    "    return total_samples/pos_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, feature_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.RNN(feature_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.rnn(x)\n",
    "        fc_out = self.fc(hidden.squeeze(0))        \n",
    "        return fc_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_run(config):\n",
    "    train_dict, val_dict, test_dict = split_dataset(patients, config['ratios'])\n",
    "    feature_dim, hidden_dim, output_dim = config['feature_dim'], config['hidden_dim'], config['output_dim']\n",
    "    model = SimpleLSTM(feature_dim, hidden_dim, output_dim)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config['lr_rate'])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    if config['pos_weight'] is not None:\n",
    "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.Tensor([config['pos_weight']]))\n",
    "    \n",
    "    train_hist, val_hist = train(model, optimizer, criterion, \n",
    "                                     train_dict, val_dict, config['max_obs_len'], config['batch_size'], \n",
    "                                     epochs=config['epochs'], window_marker=config['window_marker'])\n",
    "    return model, train_hist, val_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "t = 50, loss = 0.0474\n",
      "t = 100, loss = 0.1204\n",
      "t = 150, loss = 0.0166\n",
      "t = 200, loss = 0.0338\n",
      "Checking train accuracy!\n",
      "Got 101962 / 105000 correct (97.11)\n",
      "TP =  0 , FP =  1 , TN =  101962 , FN =  3037\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29100 / 30000 correct (97.00)\n",
      "TP =  0 , FP =  0 , TN =  29100 , FN =  900\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "t = 50, loss = 0.0768\n",
      "t = 100, loss = 0.0274\n",
      "t = 150, loss = 0.1263\n",
      "t = 200, loss = 0.0373\n",
      "Checking train accuracy!\n",
      "Got 101963 / 105000 correct (97.11)\n",
      "TP =  0 , FP =  0 , TN =  101963 , FN =  3037\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29100 / 30000 correct (97.00)\n",
      "TP =  0 , FP =  0 , TN =  29100 , FN =  900\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "t = 50, loss = 0.0270\n",
      "t = 100, loss = 0.0815\n",
      "t = 150, loss = 0.0763\n",
      "t = 200, loss = 0.0770\n",
      "Checking train accuracy!\n",
      "Got 101963 / 105000 correct (97.11)\n",
      "TP =  0 , FP =  0 , TN =  101963 , FN =  3037\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29100 / 30000 correct (97.00)\n",
      "TP =  0 , FP =  0 , TN =  29100 , FN =  900\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "t = 50, loss = 0.1272\n",
      "t = 100, loss = 0.0252\n",
      "t = 150, loss = 0.0260\n",
      "t = 200, loss = 0.0284\n",
      "Checking train accuracy!\n",
      "Got 101963 / 105000 correct (97.11)\n",
      "TP =  0 , FP =  0 , TN =  101963 , FN =  3037\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29100 / 30000 correct (97.00)\n",
      "TP =  0 , FP =  0 , TN =  29100 , FN =  900\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "t = 50, loss = 0.0332\n",
      "t = 100, loss = 0.0789\n",
      "t = 150, loss = 0.0272\n",
      "t = 200, loss = 0.0358\n",
      "Checking train accuracy!\n",
      "Got 101963 / 105000 correct (97.11)\n",
      "TP =  0 , FP =  0 , TN =  101963 , FN =  3037\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29100 / 30000 correct (97.00)\n",
      "TP =  0 , FP =  0 , TN =  29100 , FN =  900\n",
      "Precision =  0 , Recall =  0 , F1 Score =  0\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(SimpleLSTM(\n",
       "   (rnn): RNN(39, 128, batch_first=True)\n",
       "   (fc): Linear(in_features=128, out_features=30, bias=True)\n",
       " ),\n",
       " [97.10666666666667,\n",
       "  97.10761904761904,\n",
       "  97.10761904761904,\n",
       "  97.10761904761904,\n",
       "  97.10761904761904],\n",
       " [97.0, 97.0, 97.0, 97.0, 97.0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = {\n",
    "    'ratios': (.7, .2, .1),\n",
    "    'feature_dim': 39,\n",
    "    'hidden_dim': 128,\n",
    "    'output_dim': 30,\n",
    "    'max_obs_len': 30,\n",
    "    'batch_size': 16,\n",
    "    'lr_rate': 1e-3,\n",
    "    'pos_weight': None,\n",
    "    'epochs': 5,\n",
    "    'window_marker': 70\n",
    "}\n",
    "\n",
    "test_run(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "t = 50, loss = 0.3756\n",
      "t = 100, loss = 2.2152\n",
      "t = 150, loss = 0.5475\n",
      "t = 200, loss = 0.3556\n",
      "Checking train accuracy!\n",
      "Got 79128 / 105000 correct (75.36)\n",
      "TP =  1470 , FP =  24283 , TN =  77658 , FN =  1589\n",
      "Precision =  0.05708072845882033 , Recall =  0.4805491990846682 , F1 Score =  0.10204081632653063\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 22593 / 30000 correct (75.31)\n",
      "TP =  422 , FP =  6916 , TN =  22171 , FN =  491\n",
      "Precision =  0.05750885799945489 , Recall =  0.46221248630887185 , F1 Score =  0.1022906314386135\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "t = 50, loss = 0.7533\n",
      "t = 100, loss = 1.5338\n",
      "t = 150, loss = 0.7460\n",
      "t = 200, loss = 0.4481\n",
      "Checking train accuracy!\n",
      "Got 84400 / 105000 correct (80.38)\n",
      "TP =  1171 , FP =  18712 , TN =  83229 , FN =  1888\n",
      "Precision =  0.05889453301815621 , Recall =  0.38280483818241257 , F1 Score =  0.10208351495074536\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 24041 / 30000 correct (80.14)\n",
      "TP =  327 , FP =  5373 , TN =  23714 , FN =  586\n",
      "Precision =  0.057368421052631575 , Recall =  0.35815991237677985 , F1 Score =  0.09889611371540903\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "t = 50, loss = 0.5052\n",
      "t = 100, loss = 0.4140\n",
      "t = 150, loss = 0.6521\n",
      "t = 200, loss = 1.9121\n",
      "Checking train accuracy!\n",
      "Got 101911 / 105000 correct (97.06)\n",
      "TP =  48 , FP =  78 , TN =  101863 , FN =  3011\n",
      "Precision =  0.38095238095238093 , Recall =  0.015691402419091206 , F1 Score =  0.030141287284144426\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29063 / 30000 correct (96.88)\n",
      "TP =  4 , FP =  28 , TN =  29059 , FN =  909\n",
      "Precision =  0.125 , Recall =  0.004381161007667032 , F1 Score =  0.008465608465608466\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "t = 50, loss = 0.8363\n",
      "t = 100, loss = 2.2047\n",
      "t = 150, loss = 0.9043\n",
      "t = 200, loss = 1.8714\n",
      "Checking train accuracy!\n",
      "Got 81198 / 105000 correct (77.33)\n",
      "TP =  1330 , FP =  22073 , TN =  79868 , FN =  1729\n",
      "Precision =  0.05683032089903004 , Recall =  0.43478260869565216 , F1 Score =  0.10052150253193258\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 23126 / 30000 correct (77.09)\n",
      "TP =  381 , FP =  6342 , TN =  22745 , FN =  532\n",
      "Precision =  0.05667112896028559 , Recall =  0.4173055859802848 , F1 Score =  0.0997904662126768\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "t = 50, loss = 1.4445\n",
      "t = 100, loss = 1.6292\n",
      "t = 150, loss = 0.4175\n",
      "t = 200, loss = 0.3478\n",
      "Checking train accuracy!\n",
      "Got 100740 / 105000 correct (95.94)\n",
      "TP =  385 , FP =  1586 , TN =  100355 , FN =  2674\n",
      "Precision =  0.19533231861998984 , Recall =  0.12585812356979406 , F1 Score =  0.15308151093439368\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28771 / 30000 correct (95.90)\n",
      "TP =  87 , FP =  403 , TN =  28684 , FN =  826\n",
      "Precision =  0.17755102040816326 , Recall =  0.09529025191675794 , F1 Score =  0.12401995723449752\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "t = 50, loss = 0.5587\n",
      "t = 100, loss = 0.2840\n",
      "t = 150, loss = 1.1154\n",
      "t = 200, loss = 0.4806\n",
      "Checking train accuracy!\n",
      "Got 101660 / 105000 correct (96.82)\n",
      "TP =  264 , FP =  545 , TN =  101396 , FN =  2795\n",
      "Precision =  0.3263288009888752 , Recall =  0.08630271330500164 , F1 Score =  0.13650465356773528\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28967 / 30000 correct (96.56)\n",
      "TP =  63 , FP =  183 , TN =  28904 , FN =  850\n",
      "Precision =  0.25609756097560976 , Recall =  0.06900328587075576 , F1 Score =  0.10871440897325281\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "t = 50, loss = 1.7290\n",
      "t = 100, loss = 0.5411\n",
      "t = 150, loss = 0.2372\n",
      "t = 200, loss = 1.9232\n",
      "Checking train accuracy!\n",
      "Got 102011 / 105000 correct (97.15)\n",
      "TP =  131 , FP =  61 , TN =  101880 , FN =  2928\n",
      "Precision =  0.6822916666666666 , Recall =  0.042824452435436415 , F1 Score =  0.0805905875115349\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29090 / 30000 correct (96.97)\n",
      "TP =  23 , FP =  20 , TN =  29067 , FN =  890\n",
      "Precision =  0.5348837209302325 , Recall =  0.025191675794085433 , F1 Score =  0.04811715481171548\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "t = 50, loss = 0.4851\n",
      "t = 100, loss = 0.6315\n",
      "t = 150, loss = 0.7814\n",
      "t = 200, loss = 1.4250\n",
      "Checking train accuracy!\n",
      "Got 89965 / 105000 correct (85.68)\n",
      "TP =  970 , FP =  12946 , TN =  88995 , FN =  2089\n",
      "Precision =  0.06970393791319345 , Recall =  0.31709709055246815 , F1 Score =  0.11428571428571428\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 25716 / 30000 correct (85.72)\n",
      "TP =  272 , FP =  3643 , TN =  25444 , FN =  641\n",
      "Precision =  0.06947637292464878 , Recall =  0.29791894852135814 , F1 Score =  0.11267605633802816\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "t = 50, loss = 0.6463\n",
      "t = 100, loss = 1.4604\n",
      "t = 150, loss = 1.4481\n",
      "t = 200, loss = 1.3214\n",
      "Checking train accuracy!\n",
      "Got 101661 / 105000 correct (96.82)\n",
      "TP =  453 , FP =  733 , TN =  101208 , FN =  2606\n",
      "Precision =  0.38195615514333897 , Recall =  0.14808761033017326 , F1 Score =  0.21342756183745584\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28966 / 30000 correct (96.55)\n",
      "TP =  110 , FP =  231 , TN =  28856 , FN =  803\n",
      "Precision =  0.3225806451612903 , Recall =  0.12048192771084337 , F1 Score =  0.17543859649122806\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "t = 50, loss = 0.3713\n",
      "t = 100, loss = 0.3889\n",
      "t = 150, loss = 0.9382\n",
      "t = 200, loss = 0.4553\n",
      "Checking train accuracy!\n",
      "Got 99360 / 105000 correct (94.63)\n",
      "TP =  655 , FP =  3236 , TN =  98705 , FN =  2404\n",
      "Precision =  0.168337188383449 , Recall =  0.21412226217718208 , F1 Score =  0.1884892086330935\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28252 / 30000 correct (94.17)\n",
      "TP =  161 , FP =  996 , TN =  28091 , FN =  752\n",
      "Precision =  0.13915298184961106 , Recall =  0.17634173055859803 , F1 Score =  0.15555555555555556\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "t = 50, loss = 0.5051\n",
      "t = 100, loss = 0.3972\n",
      "t = 150, loss = 0.4995\n",
      "t = 200, loss = 0.5191\n",
      "Checking train accuracy!\n",
      "Got 100016 / 105000 correct (95.25)\n",
      "TP =  680 , FP =  2605 , TN =  99336 , FN =  2379\n",
      "Precision =  0.2070015220700152 , Recall =  0.22229486760379208 , F1 Score =  0.21437578814627994\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28479 / 30000 correct (94.93)\n",
      "TP =  172 , FP =  780 , TN =  28307 , FN =  741\n",
      "Precision =  0.18067226890756302 , Recall =  0.18838992332968238 , F1 Score =  0.18445040214477215\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "t = 50, loss = 0.4641\n",
      "t = 100, loss = 1.2754\n",
      "t = 150, loss = 0.3814\n",
      "t = 200, loss = 0.3447\n",
      "Checking train accuracy!\n",
      "Got 101358 / 105000 correct (96.53)\n",
      "TP =  670 , FP =  1253 , TN =  100688 , FN =  2389\n",
      "Precision =  0.3484139365574623 , Recall =  0.21902582543314808 , F1 Score =  0.2689682858289843\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28798 / 30000 correct (95.99)\n",
      "TP =  144 , FP =  433 , TN =  28654 , FN =  769\n",
      "Precision =  0.24956672443674177 , Recall =  0.15772179627601315 , F1 Score =  0.1932885906040269\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "t = 50, loss = 0.2723\n",
      "t = 100, loss = 1.1515\n",
      "t = 150, loss = 0.2800\n",
      "t = 200, loss = 1.1811\n",
      "Checking train accuracy!\n",
      "Got 87061 / 105000 correct (82.92)\n",
      "TP =  1381 , FP =  16261 , TN =  85680 , FN =  1678\n",
      "Precision =  0.07827910667724748 , Recall =  0.4514547237659366 , F1 Score =  0.1334235061108159\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 24744 / 30000 correct (82.48)\n",
      "TP =  357 , FP =  4700 , TN =  24387 , FN =  556\n",
      "Precision =  0.07059521455408345 , Recall =  0.3910186199342826 , F1 Score =  0.11959798994974874\n",
      "\n",
      "\n",
      "Epoch:  14\n",
      "t = 50, loss = 0.3904\n",
      "t = 100, loss = 2.2546\n",
      "t = 150, loss = 0.5015\n",
      "t = 200, loss = 0.3964\n",
      "Checking train accuracy!\n",
      "Got 85453 / 105000 correct (81.38)\n",
      "TP =  1355 , FP =  17843 , TN =  84098 , FN =  1704\n",
      "Precision =  0.07058026877799771 , Recall =  0.4429552141222622 , F1 Score =  0.12175944646628027\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 24422 / 30000 correct (81.41)\n",
      "TP =  432 , FP =  5097 , TN =  23990 , FN =  481\n",
      "Precision =  0.0781334780249593 , Recall =  0.47316538882803943 , F1 Score =  0.13411983855945359\n",
      "\n",
      "\n",
      "Epoch:  15\n",
      "t = 50, loss = 1.3680\n",
      "t = 100, loss = 0.3471\n",
      "t = 150, loss = 0.3433\n",
      "t = 200, loss = 0.6505\n",
      "Checking train accuracy!\n",
      "Got 92518 / 105000 correct (88.11)\n",
      "TP =  860 , FP =  10283 , TN =  91658 , FN =  2199\n",
      "Precision =  0.0771784977115678 , Recall =  0.2811376266753841 , F1 Score =  0.12110970285875229\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 26444 / 30000 correct (88.15)\n",
      "TP =  198 , FP =  2841 , TN =  26246 , FN =  715\n",
      "Precision =  0.06515301085883514 , Recall =  0.21686746987951808 , F1 Score =  0.10020242914979756\n",
      "\n",
      "\n",
      "Epoch:  16\n",
      "t = 50, loss = 0.3605\n",
      "t = 100, loss = 1.5423\n",
      "t = 150, loss = 0.3619\n",
      "t = 200, loss = 2.6550\n",
      "Checking train accuracy!\n",
      "Got 83889 / 105000 correct (79.89)\n",
      "TP =  1220 , FP =  19272 , TN =  82669 , FN =  1839\n",
      "Precision =  0.05953542845988678 , Recall =  0.3988231448185682 , F1 Score =  0.10360494246528809\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 23888 / 30000 correct (79.63)\n",
      "TP =  357 , FP =  5556 , TN =  23531 , FN =  556\n",
      "Precision =  0.06037544393708777 , Recall =  0.3910186199342826 , F1 Score =  0.1046000585994726\n",
      "\n",
      "\n",
      "Epoch:  17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 50, loss = 1.2236\n",
      "t = 100, loss = 0.3639\n",
      "t = 150, loss = 0.5560\n",
      "t = 200, loss = 0.4862\n",
      "Checking train accuracy!\n",
      "Got 101952 / 105000 correct (97.10)\n",
      "TP =  501 , FP =  490 , TN =  101451 , FN =  2558\n",
      "Precision =  0.5055499495459133 , Recall =  0.16377901274926446 , F1 Score =  0.2474074074074074\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 29043 / 30000 correct (96.81)\n",
      "TP =  128 , FP =  172 , TN =  28915 , FN =  785\n",
      "Precision =  0.4266666666666667 , Recall =  0.140197152245345 , F1 Score =  0.21104699093157464\n",
      "\n",
      "\n",
      "Epoch:  18\n",
      "t = 50, loss = 0.2991\n",
      "t = 100, loss = 0.4107\n",
      "t = 150, loss = 0.3103\n",
      "t = 200, loss = 1.2483\n",
      "Checking train accuracy!\n",
      "Got 96365 / 105000 correct (91.78)\n",
      "TP =  1109 , FP =  6685 , TN =  95256 , FN =  1950\n",
      "Precision =  0.14228894021041827 , Recall =  0.36253677672441975 , F1 Score =  0.20436745600294848\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 27488 / 30000 correct (91.63)\n",
      "TP =  244 , FP =  1843 , TN =  27244 , FN =  669\n",
      "Precision =  0.1169142309535218 , Recall =  0.2672508214676889 , F1 Score =  0.16266666666666665\n",
      "\n",
      "\n",
      "Epoch:  19\n",
      "t = 50, loss = 0.5200\n",
      "t = 100, loss = 0.3461\n",
      "t = 150, loss = 0.3434\n",
      "t = 200, loss = 0.4494\n",
      "Checking train accuracy!\n",
      "Got 101543 / 105000 correct (96.71)\n",
      "TP =  1016 , FP =  1414 , TN =  100527 , FN =  2043\n",
      "Precision =  0.4181069958847737 , Recall =  0.33213468453743056 , F1 Score =  0.3701949353251959\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28838 / 30000 correct (96.13)\n",
      "TP =  199 , FP =  448 , TN =  28639 , FN =  714\n",
      "Precision =  0.3075734157650695 , Recall =  0.21796276013143484 , F1 Score =  0.25512820512820517\n",
      "\n",
      "\n",
      "Epoch:  20\n",
      "t = 50, loss = 0.2197\n",
      "t = 100, loss = 0.3466\n",
      "t = 150, loss = 1.3182\n",
      "t = 200, loss = 1.0922\n",
      "Checking train accuracy!\n",
      "Got 96208 / 105000 correct (91.63)\n",
      "TP =  1523 , FP =  7256 , TN =  94685 , FN =  1536\n",
      "Precision =  0.17348217336826519 , Recall =  0.4978751225890814 , F1 Score =  0.25730697752998816\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 27171 / 30000 correct (90.57)\n",
      "TP =  315 , FP =  2231 , TN =  26856 , FN =  598\n",
      "Precision =  0.1237234878240377 , Recall =  0.34501642935377874 , F1 Score =  0.1821335646140503\n",
      "\n",
      "\n",
      "Epoch:  21\n",
      "t = 50, loss = 1.5857\n",
      "t = 100, loss = 0.8934\n",
      "t = 150, loss = 0.1987\n",
      "t = 200, loss = 0.6438\n",
      "Checking train accuracy!\n",
      "Got 93936 / 105000 correct (89.46)\n",
      "TP =  1573 , FP =  9578 , TN =  92363 , FN =  1486\n",
      "Precision =  0.14106358174154784 , Recall =  0.5142203334423014 , F1 Score =  0.22139338494018296\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 26637 / 30000 correct (88.79)\n",
      "TP =  371 , FP =  2821 , TN =  26266 , FN =  542\n",
      "Precision =  0.1162280701754386 , Recall =  0.4063526834611172 , F1 Score =  0.18075517661388552\n",
      "\n",
      "\n",
      "Epoch:  22\n",
      "t = 50, loss = 0.3485\n",
      "t = 100, loss = 1.0847\n",
      "t = 150, loss = 1.1189\n",
      "t = 200, loss = 1.0814\n",
      "Checking train accuracy!\n",
      "Got 100568 / 105000 correct (95.78)\n",
      "TP =  1399 , FP =  2772 , TN =  99169 , FN =  1660\n",
      "Precision =  0.33541117238072404 , Recall =  0.45733899967309577 , F1 Score =  0.3869986168741355\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 28290 / 30000 correct (94.30)\n",
      "TP =  237 , FP =  1034 , TN =  28053 , FN =  676\n",
      "Precision =  0.18646734854445318 , Recall =  0.25958378970427165 , F1 Score =  0.217032967032967\n",
      "\n",
      "\n",
      "Epoch:  23\n",
      "t = 50, loss = 0.2859\n",
      "t = 100, loss = 0.9003\n",
      "t = 150, loss = 0.2952\n",
      "t = 200, loss = 0.3090\n",
      "Checking train accuracy!\n",
      "Got 90833 / 105000 correct (86.51)\n",
      "TP =  1902 , FP =  13010 , TN =  88931 , FN =  1157\n",
      "Precision =  0.12754828326180256 , Recall =  0.6217718208564891 , F1 Score =  0.21167436425351954\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 25678 / 30000 correct (85.59)\n",
      "TP =  432 , FP =  3841 , TN =  25246 , FN =  481\n",
      "Precision =  0.10109992979171542 , Recall =  0.47316538882803943 , F1 Score =  0.16660239105283456\n",
      "\n",
      "\n",
      "Epoch:  24\n",
      "t = 50, loss = 0.7122\n",
      "t = 100, loss = 0.3752\n",
      "t = 150, loss = 0.6464\n",
      "t = 200, loss = 0.2214\n",
      "Checking train accuracy!\n",
      "Got 81500 / 105000 correct (77.62)\n",
      "TP =  2130 , FP =  22571 , TN =  79370 , FN =  929\n",
      "Precision =  0.08623132666693656 , Recall =  0.6963059823471722 , F1 Score =  0.15345821325648415\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 23182 / 30000 correct (77.27)\n",
      "TP =  528 , FP =  6433 , TN =  22654 , FN =  385\n",
      "Precision =  0.07585117080879183 , Recall =  0.5783132530120482 , F1 Score =  0.13411226822453645\n",
      "\n",
      "\n",
      "Epoch:  25\n",
      "t = 50, loss = 0.6896\n",
      "t = 100, loss = 0.6915\n",
      "t = 150, loss = 0.4830\n",
      "t = 200, loss = 0.3612\n",
      "Checking train accuracy!\n",
      "Got 95909 / 105000 correct (91.34)\n",
      "TP =  1886 , FP =  7918 , TN =  94023 , FN =  1173\n",
      "Precision =  0.1923704610363117 , Recall =  0.6165413533834586 , F1 Score =  0.2932441887584545\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 26972 / 30000 correct (89.91)\n",
      "TP =  522 , FP =  2637 , TN =  26450 , FN =  391\n",
      "Precision =  0.16524216524216523 , Recall =  0.5717415115005476 , F1 Score =  0.25638506876227896\n",
      "\n",
      "\n",
      "Epoch:  26\n",
      "t = 50, loss = 0.8674\n",
      "t = 100, loss = 0.4959\n",
      "t = 150, loss = 0.4725\n",
      "t = 200, loss = 0.8457\n",
      "Checking train accuracy!\n",
      "Got 98347 / 105000 correct (93.66)\n",
      "TP =  1662 , FP =  5256 , TN =  96685 , FN =  1397\n",
      "Precision =  0.24024284475281873 , Recall =  0.543314808761033 , F1 Score =  0.33316628244963414\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 27603 / 30000 correct (92.01)\n",
      "TP =  410 , FP =  1894 , TN =  27193 , FN =  503\n",
      "Precision =  0.1779513888888889 , Recall =  0.44906900328587074 , F1 Score =  0.25489586571339756\n",
      "\n",
      "\n",
      "Epoch:  27\n",
      "t = 50, loss = 2.6182\n",
      "t = 100, loss = 0.7632\n",
      "t = 150, loss = 0.3212\n",
      "t = 200, loss = 1.3203\n",
      "Checking train accuracy!\n",
      "Got 83822 / 105000 correct (79.83)\n",
      "TP =  2264 , FP =  20383 , TN =  81558 , FN =  795\n",
      "Precision =  0.09996909082880735 , Recall =  0.7401111474338019 , F1 Score =  0.1761456469306777\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 23592 / 30000 correct (78.64)\n",
      "TP =  571 , FP =  6066 , TN =  23021 , FN =  342\n",
      "Precision =  0.08603284616543619 , Recall =  0.6254107338444688 , F1 Score =  0.15125827814569537\n",
      "\n",
      "\n",
      "Epoch:  28\n",
      "t = 50, loss = 1.6110\n",
      "t = 100, loss = 0.5207\n",
      "t = 150, loss = 0.3681\n",
      "t = 200, loss = 0.3414\n",
      "Checking train accuracy!\n",
      "Got 97724 / 105000 correct (93.07)\n",
      "TP =  2057 , FP =  6274 , TN =  95667 , FN =  1002\n",
      "Precision =  0.24690913455767616 , Recall =  0.672441974501471 , F1 Score =  0.3611940298507462\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 27738 / 30000 correct (92.46)\n",
      "TP =  497 , FP =  1846 , TN =  27241 , FN =  416\n",
      "Precision =  0.21212121212121213 , Recall =  0.5443592552026287 , F1 Score =  0.30528255528255527\n",
      "\n",
      "\n",
      "Epoch:  29\n",
      "t = 50, loss = 1.2371\n",
      "t = 100, loss = 0.8811\n",
      "t = 150, loss = 0.5330\n",
      "t = 200, loss = 0.2489\n",
      "Checking train accuracy!\n",
      "Got 84686 / 105000 correct (80.65)\n",
      "TP =  2234 , FP =  19489 , TN =  82452 , FN =  825\n",
      "Precision =  0.10284030750817107 , Recall =  0.7303040209218699 , F1 Score =  0.1802921475264305\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 23764 / 30000 correct (79.21)\n",
      "TP =  629 , FP =  5952 , TN =  23135 , FN =  284\n",
      "Precision =  0.09557817960796232 , Recall =  0.6889375684556407 , F1 Score =  0.16786762743528155\n",
      "\n",
      "\n",
      "Epoch:  30\n",
      "t = 50, loss = 0.2990\n",
      "t = 100, loss = 0.5463\n",
      "t = 150, loss = 0.9808\n",
      "t = 200, loss = 0.4020\n",
      "Checking train accuracy!\n",
      "Got 93308 / 105000 correct (88.86)\n",
      "TP =  1719 , FP =  10352 , TN =  91589 , FN =  1340\n",
      "Precision =  0.14240742274873663 , Recall =  0.5619483491337038 , F1 Score =  0.22723066754791804\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 26612 / 30000 correct (88.71)\n",
      "TP =  358 , FP =  2833 , TN =  26254 , FN =  555\n",
      "Precision =  0.1121905358821686 , Recall =  0.39211391018619934 , F1 Score =  0.17446393762183238\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    'ratios': (.7, .2, .1),\n",
    "    'feature_dim': 39,\n",
    "    'hidden_dim': 128,\n",
    "    'output_dim': 30,\n",
    "    'max_obs_len': 30,\n",
    "    'batch_size': 16,\n",
    "    'lr_rate': 1e-3,\n",
    "    'pos_weight': 17,\n",
    "    'epochs': 30,\n",
    "    'window_marker': 70\n",
    "}\n",
    "\n",
    "model, train_hist, val_hist = test_run(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "t = 50, loss = 1.2850\n",
      "t = 100, loss = 1.4239\n",
      "Checking train accuracy!\n",
      "Got 167206 / 200000 correct (83.60)\n",
      "TP =  1730 , FP =  27836 , TN =  165476 , FN =  4958\n",
      "Precision =  0.058513157004667526 , Recall =  0.2586722488038278 , F1 Score =  0.09543774480057374\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 20886 / 25000 correct (83.54)\n",
      "TP =  198 , FP =  3497 , TN =  20688 , FN =  617\n",
      "Precision =  0.053585926928281465 , Recall =  0.24294478527607363 , F1 Score =  0.0878048780487805\n",
      "\n",
      "\n",
      "Epoch:  2\n",
      "t = 50, loss = 1.6523\n",
      "t = 100, loss = 1.5878\n",
      "Checking train accuracy!\n",
      "Got 171241 / 200000 correct (85.62)\n",
      "TP =  1670 , FP =  23741 , TN =  169571 , FN =  5018\n",
      "Precision =  0.06571957026484593 , Recall =  0.24970095693779903 , F1 Score =  0.10405308576591171\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21357 / 25000 correct (85.43)\n",
      "TP =  192 , FP =  3020 , TN =  21165 , FN =  623\n",
      "Precision =  0.05977584059775841 , Recall =  0.23558282208588957 , F1 Score =  0.09535634467345419\n",
      "\n",
      "\n",
      "Epoch:  3\n",
      "t = 50, loss = 0.7810\n",
      "t = 100, loss = 0.7605\n",
      "Checking train accuracy!\n",
      "Got 171254 / 200000 correct (85.63)\n",
      "TP =  1788 , FP =  23846 , TN =  169466 , FN =  4900\n",
      "Precision =  0.06975111180463447 , Recall =  0.2673444976076555 , F1 Score =  0.1106367180248747\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21351 / 25000 correct (85.40)\n",
      "TP =  199 , FP =  3033 , TN =  21152 , FN =  616\n",
      "Precision =  0.06157178217821782 , Recall =  0.2441717791411043 , F1 Score =  0.09834445268099827\n",
      "\n",
      "\n",
      "Epoch:  4\n",
      "t = 50, loss = 0.8324\n",
      "t = 100, loss = 0.4741\n",
      "Checking train accuracy!\n",
      "Got 172802 / 200000 correct (86.40)\n",
      "TP =  1829 , FP =  22339 , TN =  170973 , FN =  4859\n",
      "Precision =  0.07567858325057927 , Recall =  0.2734748803827751 , F1 Score =  0.11855068706248378\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21569 / 25000 correct (86.28)\n",
      "TP =  198 , FP =  2814 , TN =  21371 , FN =  617\n",
      "Precision =  0.06573705179282868 , Recall =  0.24294478527607363 , F1 Score =  0.10347530702900445\n",
      "\n",
      "\n",
      "Epoch:  5\n",
      "t = 50, loss = 0.6830\n",
      "t = 100, loss = 0.5392\n",
      "Checking train accuracy!\n",
      "Got 180075 / 200000 correct (90.04)\n",
      "TP =  1450 , FP =  14687 , TN =  178625 , FN =  5238\n",
      "Precision =  0.08985561132800396 , Recall =  0.21680622009569378 , F1 Score =  0.1270536692223439\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 22486 / 25000 correct (89.94)\n",
      "TP =  149 , FP =  1848 , TN =  22337 , FN =  666\n",
      "Precision =  0.07461191787681522 , Recall =  0.18282208588957055 , F1 Score =  0.10597439544807966\n",
      "\n",
      "\n",
      "Epoch:  6\n",
      "t = 50, loss = 0.5981\n",
      "t = 100, loss = 0.9995\n",
      "Checking train accuracy!\n",
      "Got 174923 / 200000 correct (87.46)\n",
      "TP =  1911 , FP =  20300 , TN =  173012 , FN =  4777\n",
      "Precision =  0.08603844941695556 , Recall =  0.28573564593301437 , F1 Score =  0.13225371120107962\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21822 / 25000 correct (87.29)\n",
      "TP =  194 , FP =  2557 , TN =  21628 , FN =  621\n",
      "Precision =  0.07051981097782624 , Recall =  0.23803680981595093 , F1 Score =  0.10880538418395962\n",
      "\n",
      "\n",
      "Epoch:  7\n",
      "t = 50, loss = 1.2137\n",
      "t = 100, loss = 1.2500\n",
      "Checking train accuracy!\n",
      "Got 168283 / 200000 correct (84.14)\n",
      "TP =  2531 , FP =  27560 , TN =  165752 , FN =  4157\n",
      "Precision =  0.08411152836396264 , Recall =  0.378438995215311 , F1 Score =  0.13763288833301612\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 20996 / 25000 correct (83.98)\n",
      "TP =  249 , FP =  3438 , TN =  20747 , FN =  566\n",
      "Precision =  0.06753458096013018 , Recall =  0.30552147239263805 , F1 Score =  0.11061750333185248\n",
      "\n",
      "\n",
      "Epoch:  8\n",
      "t = 50, loss = 0.7580\n",
      "t = 100, loss = 1.9385\n",
      "Checking train accuracy!\n",
      "Got 170977 / 200000 correct (85.49)\n",
      "TP =  2645 , FP =  24980 , TN =  168332 , FN =  4043\n",
      "Precision =  0.09574660633484162 , Recall =  0.3954844497607656 , F1 Score =  0.15416897385830444\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21364 / 25000 correct (85.46)\n",
      "TP =  242 , FP =  3063 , TN =  21122 , FN =  573\n",
      "Precision =  0.07322239031770045 , Recall =  0.2969325153374233 , F1 Score =  0.1174757281553398\n",
      "\n",
      "\n",
      "Epoch:  9\n",
      "t = 50, loss = 0.8703\n",
      "t = 100, loss = 0.9146\n",
      "Checking train accuracy!\n",
      "Got 173483 / 200000 correct (86.74)\n",
      "TP =  2716 , FP =  22545 , TN =  170767 , FN =  3972\n",
      "Precision =  0.10751751712125411 , Recall =  0.4061004784688995 , F1 Score =  0.1700209709224076\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21692 / 25000 correct (86.77)\n",
      "TP =  244 , FP =  2737 , TN =  21448 , FN =  571\n",
      "Precision =  0.08185172760818517 , Recall =  0.29938650306748466 , F1 Score =  0.12855637513171758\n",
      "\n",
      "\n",
      "Epoch:  10\n",
      "t = 50, loss = 0.5080\n",
      "t = 100, loss = 0.6010\n",
      "Checking train accuracy!\n",
      "Got 171193 / 200000 correct (85.60)\n",
      "TP =  3300 , FP =  25419 , TN =  167893 , FN =  3388\n",
      "Precision =  0.11490650788676486 , Recall =  0.4934210526315789 , F1 Score =  0.18640381845397802\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21367 / 25000 correct (85.47)\n",
      "TP =  285 , FP =  3103 , TN =  21082 , FN =  530\n",
      "Precision =  0.08412042502951594 , Recall =  0.3496932515337423 , F1 Score =  0.13561741613133477\n",
      "\n",
      "\n",
      "Epoch:  11\n",
      "t = 50, loss = 0.3341\n",
      "t = 100, loss = 0.6086\n",
      "Checking train accuracy!\n",
      "Got 173338 / 200000 correct (86.67)\n",
      "TP =  3316 , FP =  23290 , TN =  170022 , FN =  3372\n",
      "Precision =  0.12463354130647222 , Recall =  0.4958133971291866 , F1 Score =  0.19919505015918784\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21620 / 25000 correct (86.48)\n",
      "TP =  286 , FP =  2851 , TN =  21334 , FN =  529\n",
      "Precision =  0.09116990755498884 , Recall =  0.350920245398773 , F1 Score =  0.14473684210526316\n",
      "\n",
      "\n",
      "Epoch:  12\n",
      "t = 50, loss = 0.8924\n",
      "t = 100, loss = 1.0239\n",
      "Checking train accuracy!\n",
      "Got 176056 / 200000 correct (88.03)\n",
      "TP =  3377 , FP =  20633 , TN =  172679 , FN =  3311\n",
      "Precision =  0.1406497292794669 , Recall =  0.5049342105263158 , F1 Score =  0.22001433318131475\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 21950 / 25000 correct (87.80)\n",
      "TP =  278 , FP =  2513 , TN =  21672 , FN =  537\n",
      "Precision =  0.09960587603009674 , Recall =  0.3411042944785276 , F1 Score =  0.15418746533555186\n",
      "\n",
      "\n",
      "Epoch:  13\n",
      "t = 50, loss = 1.6852\n",
      "t = 100, loss = 0.7258\n",
      "Checking train accuracy!\n",
      "Got 176230 / 200000 correct (88.11)\n",
      "TP =  3878 , FP =  20960 , TN =  172352 , FN =  2810\n",
      "Precision =  0.15613173363394797 , Recall =  0.5798444976076556 , F1 Score =  0.2460191587895705\n",
      "\n",
      "Checking val accuracy!\n",
      "Got 22027 / 25000 correct (88.11)\n",
      "TP =  308 , FP =  2466 , TN =  21719 , FN =  507\n",
      "Precision =  0.1110310021629416 , Recall =  0.37791411042944784 , F1 Score =  0.17163555307885206\n",
      "\n",
      "\n",
      "Epoch:  14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b8d2177a16f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m }\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-30bba8c3241d>\u001b[0m in \u001b[0;36mtest_run\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     10\u001b[0m     train_hist, val_hist = train(model, optimizer, criterion, \n\u001b[1;32m     11\u001b[0m                                      \u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_obs_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                      epochs=config['epochs'], window_marker=config['window_marker'])\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_hist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_hist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-af3cd224dda9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, loss_fn, train_dict, val_dict, max_obs_len, batch_size, epochs, print_every, window_marker)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_obs_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_marker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cd71c1ee836c>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatient_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mpatient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_patient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_obs_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow_marker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mpatient_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mpatient_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SepsisLabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d07abfaa9dff>\u001b[0m in \u001b[0;36mprocess_patient\u001b[0;34m(patient, max_len, window_marker)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msepsis_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SepsisLabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobs_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mprocess_longer_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msepsis_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_marker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mobs_len\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mprocess_shorter_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msepsis_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mobs_len\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d07abfaa9dff>\u001b[0m in \u001b[0;36mprocess_shorter_obs\u001b[0;34m(patient, sepsis_idx, max_len)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpatient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   6183\u001b[0m             other = DataFrame(other.values.reshape((1, len(other))),\n\u001b[1;32m   6184\u001b[0m                               \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6185\u001b[0;31m                               columns=combined_columns)\n\u001b[0m\u001b[1;32m   6186\u001b[0m             \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimedelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_columns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n\u001b[0;32m--> 379\u001b[0;31m                                          copy=copy)\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_init_ndarray\u001b[0;34m(self, values, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_blocks\u001b[0;34m(blocks, axes)\u001b[0m\n\u001b[1;32m   4857\u001b[0m                                      placement=slice(0, len(axes[0])))]\n\u001b[1;32m   4858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4859\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4860\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4861\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m   3280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3489\u001b[0m         \u001b[0mmgr_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3490\u001b[0m         \u001b[0mtot_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3491\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3492\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3493\u001b[0m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_config = {\n",
    "    'ratios': (.8, .1, .1),\n",
    "    'feature_dim': 39,\n",
    "    'hidden_dim': 256,\n",
    "    'output_dim': 50,\n",
    "    'max_obs_len': 50,\n",
    "    'batch_size': 32,\n",
    "    'lr_rate': 1e-4,\n",
    "    'pos_weight': 17,\n",
    "    'epochs': 30,\n",
    "    'window_marker': 70\n",
    "}\n",
    "\n",
    "model, train_hist, val_hist = test_run(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
